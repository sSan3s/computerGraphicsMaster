# Human-Object Interaction (HOI) 3D Pipeline

## Project Overview

This project implements a complete pipeline for extracting and visualizing Human-Object Interactions (HOI) from 2D videos in 3D space.

### Pipeline Architecture
```
Video Input
    â†“
[2D Detection & Tracking]
â”œâ”€ YOLO: Object detection (humans + objects)
â””â”€ ByteTrack: Multi-object tracking
    â†“
[Pose Estimation]
â”œâ”€ YOLO-Pose: 2D keypoint extraction (17 joints)
â””â”€ MotionBERT: 2Dâ†’3D pose lifting
    â†“
[3D Reconstruction]
â”œâ”€ 6D Pose Estimation: Object position + rotation
â””â”€ HAKE: HOI relationship inference
    â†“
[Visualization]
â”œâ”€ 2D Overlay: Annotated video with bounding boxes
â””â”€ Open3D: 3D scene reconstruction
    â†“
[Output]
â”œâ”€ JSONL: Structured data for each frame
â”œâ”€ 2D Video: Annotated visualization
â””â”€ 3D Video: 3D scene rendering
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10.13

### Installation

```bash
# 1. Clone repository
git clone https://github.com/leasw/123whddnjs.git
cd 123whddnjs

# 2. Create virtual environment
python3.10 -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# 3. Install dependencies
pip install --upgrade pip wheel setuptools
pip install -r requirements_updated.txt
```

### Download Model Weights

```bash
# YOLO object detection
wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l.pt -O yolo12l.pt

# YOLO pose estimation
wget https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11l-pose.pt
```

## ğŸ’» Usage

### Basic 2D Pipeline
```bash
python run_pipeline.py \
  --source test_video/demo_3.mp4 \
  --yolo yolo12l.pt \
  --pose_weight yolo11l-pose.pt \
  --out results/output_2d.jsonl \
  --save_vis results/output_2d.mp4 \
  --draw_parts \
  --show
```

### Full 3D Pipeline
```bash
python run_pipeline_3d.py \
  --source test_video/demo_3.mp4 \
  --yolo yolo12l.pt \
  --pose_weight yolo11l-pose.pt \
  --out results/output_3d.jsonl \
  --save_vis results/output_2d_vis.mp4 \
  --save_3d_vis results/output_3d_render.mp4 \
  --enable_3d \
  --show_3d \
  --temporal_window 10
```

### Parameters

| Parameter | Description | Default |
|-----------|-------------|---------|
| `--source` | Input video path or camera index | Required |
| `--yolo` | YOLO model weights path | Required |
| `--pose_weight` | Pose estimation model path | None |
| `--out` | Output JSONL file path | output.jsonl |
| `--save_vis` | Save 2D annotated video | None |
| `--save_3d_vis` | Save 3D rendered video | None |
| `--enable_3d` | Enable 3D processing | False |
| `--show` | Display 2D visualization | False |
| `--show_3d` | Display 3D visualization | False |
| `--conf` | Detection confidence threshold | 0.25 |
| `--iou` | Detection IoU threshold | 0.5 |
| `--temporal_window` | Window size for temporal smoothing | 10 |

## ğŸ“ Project Structure

```
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ detector_yolo.py      # YOLO object detection
â”‚   â”œâ”€â”€ tracker.py             # ByteTrack multi-object tracking
â”‚   â”œâ”€â”€ pose_adapter.py        # 2D pose estimation
â”‚   â”œâ”€â”€ hake_adapter.py        # HOI relationship inference
â”‚   â”œâ”€â”€ motionbert_adapter.py  # 2Dâ†’3D pose lifting [NEW]
â”‚   â”œâ”€â”€ pose6d_adapter.py      # 6D object pose estimation [NEW]
â”‚   â”œâ”€â”€ visualizer_3d.py       # Open3D 3D visualization [NEW]
â”‚   â”œâ”€â”€ schemas.py             # Data schemas
â”‚   â””â”€â”€ utils_io.py            # I/O utilities
â”œâ”€â”€ test_video/                # Sample videos
â”œâ”€â”€ run_pipeline.py            # 2D pipeline
â”œâ”€â”€ run_pipeline_3d.py         # 3D pipeline [NEW]
â””â”€â”€ test_3d_pipeline.sh        # Test script [NEW]
```

## ğŸ“Š Output Format

### JSONL Structure
```json
{
  "frame_index": 0,
  "timestamp_ms": 0,
  "humans": [
    {
      "track_id": 1,
      "bbox_xyxy": [x1, y1, x2, y2],
      "score": 0.95,
      "keypoints_3d": [[x, y, z], ...]  // 17 joints
    }
  ],
  "objects": [
    {
      "track_id": 100001,
      "bbox_xyxy": [x1, y1, x2, y2],
      "category": "cup",
      "score": 0.89,
      "pose_6d": {
        "position": [x, y, z],
        "rotation": [roll, pitch, yaw],
        "quaternion": [x, y, z, w]
      }
    }
  ],
  "hoi": [
    {
      "human_id": 1,
      "object_id": 100001,
      "verb": "hold",
      "score": 0.80,
      "part": "hand",
      "triplet": ["person", "hold", "cup"]
    }
  ]
}
```

## ğŸ”§ Module Details

### New 3D Processing Modules

1. **MotionBERT Adapter** (`src/motionbert_adapter.py`)
   - Converts 2D keypoints to 3D coordinates
   - Temporal smoothing for consistency
   - Baseline heuristic method included

2. **6D Pose Estimator** (`src/pose6d_adapter.py`)
   - Estimates object 3D position from bbox
   - Heuristic rotation estimation
   - Camera intrinsics calibration support

3. **Open3D Visualizer** (`src/visualizer_3d.py`)
   - Real-time 3D scene rendering
   - Human skeleton visualization
   - Object mesh rendering
   - HOI relationship visualization

## ğŸ“ˆ Performance

| Component | FPS | GPU Memory |
|-----------|-----|------------|
| YOLO Detection | ~30 | 2GB |
| Pose Estimation | ~25 | 1GB |
| 3D Processing | ~20 | 1GB |
| Open3D Rendering | ~15 | 512MB |

## ğŸ¯ Future Improvements

- [ ] Real HAKE model integration (currently using heuristics)
- [ ] MotionBERT checkpoint integration
- [ ] Advanced 6D pose models (OnePose++, CosyPose)
- [ ] Multi-person 3D pose optimization
- [ ] Real-time optimization
- [ ] Web interface for visualization

## ğŸ“ References

- YOLO: [Ultralytics](https://github.com/ultralytics/ultralytics)
- ByteTrack: [Supervision](https://github.com/roboflow/supervision)
- MotionBERT: [Paper](https://github.com/Walter0807/MotionBERT)
- HAKE: [Paper](http://hake-mvig.cn/)
- Open3D: [Documentation](http://www.open3d.org/)

## ğŸ“œ License

MIT License

## ğŸ‘¥ Team

- Boo Seokkyeong
- Kim Taehyeon
- Yoo Sunghwan
- Lee Jongwon

Course: Topics in Computer Graphics  
Professor: Sabina Umirzakova
